<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Python on Himalaya's Dev Journal</title><link>https://histty.in/tech/python/</link><description>Recent content in Python on Himalaya's Dev Journal</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Thu, 27 Nov 2025 15:55:41 +0530</lastBuildDate><atom:link href="https://histty.in/tech/python/index.xml" rel="self" type="application/rss+xml"/><item><title>Learning Llm</title><link>https://histty.in/projects/learning-llm/</link><pubDate>Wed, 26 Nov 2025 00:00:00 +0000</pubDate><guid>https://histty.in/projects/learning-llm/</guid><description>&lt;h2 id="problem"&gt;Problem&lt;/h2&gt;
&lt;h2 id="solution"&gt;Solution&lt;/h2&gt;
&lt;h2 id="architecture--stack"&gt;Architecture / Stack&lt;/h2&gt;
&lt;h2 id="what-i-learned"&gt;What I learned&lt;/h2&gt;
&lt;h2 id="screenshots-or-demo"&gt;Screenshots or Demo&lt;/h2&gt;</description></item><item><title>Scalable LLM Deployment on AWS with Ray Serve and FastAPI</title><link>https://histty.in/blog/deploying-llms-aws-ray-serve/</link><pubDate>Sat, 22 Nov 2025 00:00:00 +0000</pubDate><guid>https://histty.in/blog/deploying-llms-aws-ray-serve/</guid><description>A guide to deploying open-source LLMs using Ray Serve for orchestration and FastAPI for the serving layer on AWS infrastructure.</description></item></channel></rss>